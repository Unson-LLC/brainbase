#!/usr/bin/env node
/**
 * ops-department Auto Refactoring Script
 *
 * Self-hosted GitHub Actionsãƒ©ãƒ³ãƒŠãƒ¼ã§AI CLIï¼ˆCodex/Claudeï¼‰ã‚’ä½¿ç”¨ã—ã¦
 * refactoring-specialist ãŒæœªãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°é ˜åŸŸã‚’ç‰¹å®šã—ã€
 * å®Ÿéš›ã«ã‚³ãƒ¼ãƒ‰ã‚’ä¿®æ­£ã—ã¦PRä½œæˆã™ã‚‹ã€‚
 *
 * å®Ÿè¡Œã‚¿ã‚¤ãƒŸãƒ³ã‚°: 3æ™‚é–“ã”ã¨ (0:00, 3:00, 6:00, 9:00, 12:00, 15:00, 18:00, 21:00 UTC)
 * å®Ÿè¡Œç’°å¢ƒ: GitHub Actions (self-hosted runner)
 *
 * æˆ¦ç•¥:
 * 1. ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°å±¥æ­´ã‚’èª­ã¿è¾¼ã¿ï¼ˆrefactoring-history.jsonï¼‰
 * 2. ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã‚’ã‚¹ã‚­ãƒ£ãƒ³ã—ã¦æœªãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°é ˜åŸŸã‚’ç‰¹å®š
 * 3. refactoring-specialist ãŒå®Ÿéš›ã«ã‚³ãƒ¼ãƒ‰ã‚’ä¿®æ­£
 * 4. çµæœã‚’ refactoring-result.json ã¨ã—ã¦å‡ºåŠ›ï¼ˆå±¥æ­´æ›´æ–°ã¯åˆ¥ã‚¹ã‚¯ãƒªãƒ—ãƒˆã§baseã¸ç›´æ¥åæ˜ ï¼‰
 *
 * Usage:
 *   node scripts/ops-team-review.cjs [--dry-run] [--scan-only]
 */

const { spawn, execSync } = require("child_process");
const crypto = require("crypto");
const fs = require("fs");
const path = require("path");

// ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«
const HISTORY_FILE = "refactoring-history.json";
const RESULT_FILE = "refactoring-result.json";

const WORKFLOW_FILE =
  process.env.OPS_REFACTOR_WORKFLOW_FILE ||
  "ops-department-auto-refactoring.yml";

const JUDGE_THRESHOLD = Number.parseInt(
  process.env.OPS_REFACTOR_JUDGE_THRESHOLD || "80",
  10,
);
const JUDGE_MAX_ATTEMPTS = Number.parseInt(
  process.env.OPS_REFACTOR_MAX_ATTEMPTS || "3",
  10,
);
const JUDGE_MAX_DIFF_CHARS = Number.parseInt(
  process.env.OPS_REFACTOR_JUDGE_MAX_DIFF_CHARS || "12000",
  10,
);

const REFACTOR_TIMEOUT_MS = Number.parseInt(
  process.env.OPS_REFACTOR_TIMEOUT_MS || "600000",
  10,
);

const HOTSPOT_SINCE_DAYS = Number.parseInt(
  process.env.OPS_REFACTOR_HOTSPOT_SINCE_DAYS || "30",
  10,
);

const COOLDOWN_DAYS = Number.parseInt(
  process.env.OPS_REFACTOR_COOLDOWN_DAYS || "30",
  10,
);

const TARGET_TOP_N = Number.parseInt(
  process.env.OPS_REFACTOR_TARGET_TOP_N || "20",
  10,
);

const REFACTOR_TIER = (process.env.OPS_REFACTOR_TIER || "small").toLowerCase();

const REFACTOR_SOURCE_DIRS = ["public/modules", "server", "lib"];

const MAX_CHANGED_FILES = Number.parseInt(
  process.env.OPS_REFACTOR_MAX_FILES || "10",
  10,
);
const MAX_CHANGED_LINES = Number.parseInt(
  process.env.OPS_REFACTOR_MAX_LINES || "400",
  10,
);

// refactoring-specialist è¨­å®š
const REFACTORING_SPECIALIST = {
  model: process.env.CODEX_MODEL || process.env.AI_MODEL || "gpt-5-codex",
  role: "Refactoring Specialist - Implements actual code improvements",
  skills: [
    "refactoring-workflow",
    "verify-first-debugging",
    "architecture-patterns",
  ],
  systemPrompt: `You are the Refactoring Specialist in the ops-department.

Your role: Identify and IMPLEMENT actual refactoring improvements in the codebase.

Skills you have access to:
- refactoring-workflow: 3-Phaseæ®µéšçš„ç§»è¡Œã€æ—¢å­˜æ©Ÿèƒ½ä¿è­·
- verify-first-debugging: è¨¼æ‹ éšå±¤ã§æ¤œè¨¼â†’ä»®èª¬ç¦æ­¢â†’æ ¹æœ¬åŸå› ä¿®æ­£
- architecture-patterns: EventBus/DI/Reactive/Serviceæº–æ‹ ãƒã‚§ãƒƒã‚¯

IMPORTANT: You must ACTUALLY MODIFY the code files, not just suggest improvements.

Refactor constraints:
- Tier: ${REFACTOR_TIER}
- Keep changes incremental and backward compatible.
- Do NOT modify workflow files under .github/workflows/ or package-lock.json.
- Keep PR size small:
  - Max changed files (guard): ${MAX_CHANGED_FILES}
  - Max changed lines (guard): ${MAX_CHANGED_LINES}
- If you must change runtime behavior, clearly explain why and add/update tests.

Tier guidelines:
- small: touch 1-3 files, prefer local refactors (extract helpers/components, naming, reduce duplication).
- medium: up to ~10 files within the same area, allowed to extract shared helpers/components inside that area.

Refactoring priorities:
1. Code duplication (DRY violations)
2. Complex functions (>50 lines, high cyclomatic complexity)
3. Poor naming (unclear variable/function names)
4. Missing error handling
5. Architecture pattern violations

For each file you review:
1. Identify concrete refactoring opportunities
2. IMPLEMENT the changes directly in the code
3. Ensure backward compatibility
4. Provide a summary of changes made

Output format:
{
  "refactored": true/false,
  "files_modified": ["path/to/file1.ts", "path/to/file2.ts"],
  "changes_summary": "Description of refactoring applied",
  "area": "Component/Module name (e.g., 'Authentication', 'API Handlers', 'UI Components')"
}`,
};

/**
 * Codex CLIã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ
 */
async function generateWithCodex(systemPrompt, userPrompt, options = {}) {
  const { timeout = 300000 } = options;
  const codexPath = process.env.CODEX_CLI_PATH || "codex";
  const reasoningEffort = process.env.CODEX_REASONING_EFFORT || "high";
  const homeDir =
    process.env.REAL_HOME ||
    process.env.HOME ||
    process.env.USERPROFILE ||
    "/tmp";
  const outputFilePath = path.join(
    process.cwd(),
    `.codex-last-message-${Date.now()}-${Math.random().toString(36).slice(2)}.txt`,
  );
  const combinedPrompt = `${systemPrompt}\n\nUser Request:\n${userPrompt}`;

  console.log(
    `[Codex CLI] å®Ÿè¡Œé–‹å§‹ (HOME=${homeDir}, model=${REFACTORING_SPECIALIST.model})`,
  );

  return new Promise((resolve, reject) => {
    const args = [
      "exec",
      "--dangerously-bypass-approvals-and-sandbox",
      "--skip-git-repo-check",
      "-c",
      `model_reasoning_effort="${reasoningEffort}"`,
      "--output-last-message",
      outputFilePath,
    ];
    if (REFACTORING_SPECIALIST.model) {
      args.push("--model", REFACTORING_SPECIALIST.model);
    }
    args.push("-");

    const child = spawn(codexPath, args, {
      env: {
        ...process.env,
        HOME: homeDir,
      },
      stdio: ["pipe", "pipe", "pipe"],
    });

    child.stdin.write(combinedPrompt);
    child.stdin.end();

    let stdout = "";
    let stderr = "";

    child.stdout.on("data", (data) => {
      stdout += data.toString();
    });

    child.stderr.on("data", (data) => {
      stderr += data.toString();
    });

    const timer = setTimeout(() => {
      console.error(`[Codex CLI] ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ (${timeout}ms)`);
      child.kill("SIGTERM");
      reject(new Error(`Codex CLI timed out after ${timeout}ms`));
    }, timeout);

    child.on("close", (code) => {
      clearTimeout(timer);
      let lastMessage = "";

      try {
        if (fs.existsSync(outputFilePath)) {
          lastMessage = fs.readFileSync(outputFilePath, "utf-8").trim();
          fs.unlinkSync(outputFilePath);
        }
      } catch (readError) {
        console.warn(
          `[Codex CLI] æœ€çµ‚ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸èª­ã¿è¾¼ã¿å¤±æ•—: ${readError.message}`,
        );
      }

      if (code !== 0) {
        reject(
          new Error(
            `Codex CLI exited with code ${code}: ${stderr || stdout.substring(0, 200)}`,
          ),
        );
        return;
      }

      resolve(lastMessage || stdout.trim());
    });

    child.on("error", (error) => {
      clearTimeout(timer);
      reject(new Error(`Codex CLI spawn failed: ${error.message}`));
    });
  });
}

/**
 * Claude CLIã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ï¼‰
 */
async function generateWithClaude(systemPrompt, userPrompt, options = {}) {
  const { timeout = 300000 } = options;
  const homeDir =
    process.env.REAL_HOME ||
    process.env.HOME ||
    process.env.USERPROFILE ||
    "/tmp";
  const rawClaudeCommand = (
    process.env.CLAUDE_CLI_COMMAND || "npx @anthropic-ai/claude-code"
  ).trim();
  const claudeCommandParts = rawClaudeCommand.split(/\s+/).filter(Boolean);
  const claudeCliCommand = claudeCommandParts[0];
  const claudeCliArgs = claudeCommandParts.slice(1);

  console.log(`[Claude CLI] å®Ÿè¡Œé–‹å§‹ (HOME=${homeDir})`);

  return new Promise((resolve, reject) => {
    const args = [
      ...claudeCliArgs,
      "--print",
      "--dangerously-skip-permissions",
      "--system-prompt",
      systemPrompt,
      userPrompt,
    ];

    const child = spawn(claudeCliCommand, args, {
      env: {
        ...process.env,
        HOME: homeDir,
        CLAUDE_CODE_DISABLE_TELEMETRY: "1",
      },
      stdio: ["pipe", "pipe", "pipe"],
    });

    child.stdin.end();

    let stdout = "";
    let stderr = "";

    child.stdout.on("data", (data) => {
      stdout += data.toString();
    });

    child.stderr.on("data", (data) => {
      stderr += data.toString();
    });

    const timer = setTimeout(() => {
      console.error(`[Claude CLI] ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ (${timeout}ms)`);
      child.kill("SIGTERM");
      reject(new Error(`Claude CLI timed out after ${timeout}ms`));
    }, timeout);

    child.on("close", (code) => {
      clearTimeout(timer);

      if (code !== 0) {
        reject(
          new Error(
            `Claude CLI exited with code ${code}: ${stderr || stdout.substring(0, 200)}`,
          ),
        );
        return;
      }

      resolve(stdout.trim());
    });

    child.on("error", (error) => {
      clearTimeout(timer);
      reject(new Error(`Claude CLI spawn failed: ${error.message}`));
    });
  });
}

/**
 * AI CLIãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚’é¸æŠã—ã¦ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ
 */
async function generateWithAI(systemPrompt, userPrompt, options = {}) {
  const backend = (process.env.AI_CLI_BACKEND || "codex").toLowerCase();

  if (backend === "claude") {
    return generateWithClaude(systemPrompt, userPrompt, options);
  }

  if (backend !== "codex") {
    throw new Error(`Unsupported AI_CLI_BACKEND: ${backend}`);
  }

  return generateWithCodex(systemPrompt, userPrompt, options);
}

function sha256(text) {
  return crypto.createHash("sha256").update(text).digest("hex");
}

function getRepoStateFingerprint() {
  const status = execSync("git status --porcelain || true", {
    encoding: "utf-8",
    maxBuffer: 10 * 1024 * 1024,
  });
  const diff = execSync("git diff || true", {
    encoding: "utf-8",
    maxBuffer: 50 * 1024 * 1024,
  });
  return sha256(`${status}\n---\n${diff}`);
}

function getActionableChangedFiles() {
  let tracked = "";
  let untracked = "";
  try {
    tracked = execSync("git diff --name-only || true", {
      encoding: "utf-8",
      maxBuffer: 10 * 1024 * 1024,
    });
  } catch (_error) {
    tracked = "";
  }

  try {
    untracked = execSync("git ls-files --others --exclude-standard || true", {
      encoding: "utf-8",
      maxBuffer: 10 * 1024 * 1024,
    });
  } catch (_error) {
    untracked = "";
  }

  const all = new Set(
    `${tracked}\n${untracked}`
      .split("\n")
      .map((s) => s.trim())
      .filter(Boolean),
  );

  return Array.from(all)
    .filter((f) => f !== "ops-department-refactoring.md")
    .sort();
}

function discardWorkingTreeChanges() {
  try {
    execSync("git restore --staged --worktree .", { stdio: "inherit" });
  } catch (error) {
    console.warn("âš ï¸  git restore failed:", error.message);
  }

  let untracked = [];
  try {
    const out = execSync("git ls-files --others --exclude-standard || true", {
      encoding: "utf-8",
      maxBuffer: 10 * 1024 * 1024,
    }).trim();
    if (out) untracked = out.split("\n").filter(Boolean);
  } catch (_error) {
    untracked = [];
  }

  for (const p of untracked) {
    try {
      fs.rmSync(p, { recursive: true, force: true });
    } catch (_error) {
      // ignore
    }
  }
}

/**
 * ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°å±¥æ­´ã‚’èª­ã¿è¾¼ã¿
 */
function loadRefactoringHistory() {
  if (!fs.existsSync(HISTORY_FILE)) {
    return { areas: [], last_updated: null };
  }

  try {
    const content = fs.readFileSync(HISTORY_FILE, "utf-8");
    return JSON.parse(content);
  } catch (error) {
    console.warn("å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿å¤±æ•—:", error.message);
    return { areas: [], last_updated: null };
  }
}

/**
 * ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã‚’ã‚¹ã‚­ãƒ£ãƒ³ã—ã¦é ˜åŸŸãƒªã‚¹ãƒˆã‚’ä½œæˆ
 */
function scanCodebase() {
  const areas = new Set();

  REFACTOR_SOURCE_DIRS.forEach((dir) => {
    if (!fs.existsSync(dir)) return;

    const files = execSync(`git ls-files "${dir}"`, {
      encoding: "utf-8",
      maxBuffer: 10 * 1024 * 1024,
    })
      .trim()
      .split("\n")
      .filter(Boolean);

    files
      .filter((file) => /\.(cjs|mjs|js|tsx?|jsx?)$/.test(file))
      .forEach((file) => {
        const rawArea = path.dirname(file);
        if (!rawArea || rawArea === ".") return;

        if (rawArea) areas.add(rawArea);
      });
  });

  return Array.from(areas).sort();
}

/**
 * ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‹ã‚‰ "area"ï¼ˆãã®ã¾ã¾ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼‰ã‚’æ­£è¦åŒ–
 */
function normalizeAreaFromFilePath(filePath) {
  const rawArea = path.dirname(filePath);
  if (!rawArea || rawArea === ".") return "";
  return rawArea;
}

/**
 * ãƒ›ãƒƒãƒˆã‚¹ãƒãƒƒãƒˆã‚¹ã‚³ã‚¢ï¼ˆæœ€è¿‘å¤‰æ›´ãŒå¤šã„é ˜åŸŸï¼‰ã‚’è¨ˆç®—
 */
function computeHotspotScores(params = {}) {
  const sinceDaysRaw = params.sinceDays ?? HOTSPOT_SINCE_DAYS;
  const sinceDays = Number.isFinite(sinceDaysRaw) ? sinceDaysRaw : 0;
  const scores = new Map();

  if (sinceDays <= 0) return scores;

  let logOutput = "";
  try {
    logOutput = execSync(
      `git log --since="${sinceDays} days ago" --name-only --pretty=format: --no-merges`,
      {
        encoding: "utf-8",
        maxBuffer: 50 * 1024 * 1024,
      },
    );
  } catch (_error) {
    return scores;
  }

  logOutput
    .split("\n")
    .map((line) => line.trim())
    .filter(Boolean)
    .forEach((file) => {
      if (!REFACTOR_SOURCE_DIRS.some((dir) => file.startsWith(`${dir}/`))) {
        return;
      }
      if (!/\.(cjs|mjs|js|tsx?|jsx?)$/.test(file)) return;

      const area = normalizeAreaFromFilePath(file);
      if (!area) return;

      scores.set(area, (scores.get(area) || 0) + 1);
    });

  return scores;
}

function getLatestHistoryEntryByArea(history) {
  const latestByArea = new Map();
  for (const entry of history?.areas || []) {
    if (!entry?.area) continue;
    const existing = latestByArea.get(entry.area);
    if (!existing) {
      latestByArea.set(entry.area, entry);
      continue;
    }

    const existingTs = Date.parse(existing.refactored_at || "") || 0;
    const nextTs = Date.parse(entry.refactored_at || "") || 0;
    if (nextTs >= existingTs) {
      latestByArea.set(entry.area, entry);
    }
  }
  return latestByArea;
}

function isAreaEligible(params) {
  const { entry, cooldownDays } = params;

  if (!entry) return true;

  // Don't create parallel PRs for the same area.
  if (entry.pr_status === "open") return false;

  // If it was closed (not merged), retry.
  if (entry.pr_status === "closed") return true;

  const refactoredAt = Date.parse(entry.refactored_at || "");
  if (!Number.isFinite(refactoredAt)) return true;

  const cooldownMs = Math.max(0, cooldownDays) * 24 * 60 * 60 * 1000;
  return Date.now() - refactoredAt >= cooldownMs;
}

/**
 * æ¬¡ã«å¯¾è±¡ã¨ã™ã‚‹é ˜åŸŸã‚’é¸ã¶ï¼ˆãƒ›ãƒƒãƒˆã‚¹ãƒãƒƒãƒˆå„ªå…ˆ + ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ï¼‰
 */
function findEligibleAreas(allAreas, history, params = {}) {
  const cooldownDaysRaw = params.cooldownDays ?? COOLDOWN_DAYS;
  const cooldownDays = Number.isFinite(cooldownDaysRaw) ? cooldownDaysRaw : 0;
  const latestByArea = getLatestHistoryEntryByArea(history);

  return allAreas.filter((area) =>
    isAreaEligible({ entry: latestByArea.get(area), cooldownDays }),
  );
}

function selectTargetArea(eligibleAreas, hotspotScores, params = {}) {
  const topNRaw = params.topN ?? TARGET_TOP_N;
  const topN = Number.isFinite(topNRaw) ? Math.max(1, topNRaw) : 20;

  const scored = eligibleAreas
    .map((area) => ({ area, score: hotspotScores.get(area) || 0 }))
    .sort(
      (a, b) =>
        b.score - a.score ||
        a.area.localeCompare(b.area, "en", { numeric: true }),
    );

  if (scored.length === 0) return null;

  // If everything is cold, just take the first.
  const head = scored[0];
  if (head.score === 0) return head.area;

  const top = scored.slice(0, topN);
  const maxScore = top[0]?.score ?? 0;
  const tied = top.filter((row) => row.score === maxScore);
  return tied[0]?.area || head.area;
}

/**
 * é ˜åŸŸã®ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—
 */
function getFilesInArea(area) {
  try {
    const baseDir = area;
    const files = execSync(`git ls-files "${baseDir}"`, {
      encoding: "utf-8",
      maxBuffer: 10 * 1024 * 1024,
    })
      .trim()
      .split("\n")
      .filter(Boolean)
      .filter((file) => path.dirname(file) === baseDir)
      .filter((file) => /\.(cjs|mjs|js|tsx?|jsx?)$/.test(file));

    return files;
  } catch (error) {
    console.warn(`é ˜åŸŸ ${area} ã®ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—å¤±æ•—:`, error.message);
    return [];
  }
}

/**
 * ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’å–å¾—
 */
function getFileContent(filePath) {
  try {
    return fs.readFileSync(filePath, "utf-8");
  } catch (error) {
    console.warn(`ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿å¤±æ•— (${filePath}):`, error.message);
    return "";
  }
}

/**
 * refactoring-specialistã«ã‚ˆã‚‹ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°å®Ÿè¡Œ
 */
async function refactorArea(area, files) {
  console.log(`\nğŸ”¨ Refactoring area: ${area}`);
  console.log(`  ğŸ“ Files: ${files.length}`);

  if (files.length === 0) {
    return null;
  }

  // Keep scope disciplined by limiting context size based on tier.
  const tierPromptMaxFiles = REFACTOR_TIER === "medium" ? 10 : 3;
  const promptMaxFiles = Math.min(
    Math.max(1, tierPromptMaxFiles),
    Number.isFinite(MAX_CHANGED_FILES) && MAX_CHANGED_FILES > 0
      ? MAX_CHANGED_FILES
      : tierPromptMaxFiles,
  );
  const contentCharLimit = REFACTOR_TIER === "medium" ? 12000 : 8000;

  const ranked = files
    .map((file) => {
      const content = getFileContent(file);
      const lines = content ? content.split(/\r\n|\r|\n/).length : 0;
      return { file, lines, content };
    })
    .sort((a, b) => b.lines - a.lines || a.file.localeCompare(b.file, "en"));

  const fileContents = ranked.slice(0, promptMaxFiles).map((f) => ({
    path: f.file,
    lines: f.lines,
    content: f.content.slice(0, contentCharLimit),
  }));

  const userPrompt = `ä»¥ä¸‹ã®é ˜åŸŸã®ã‚³ãƒ¼ãƒ‰ã‚’ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ã—ã¦ãã ã•ã„:

é ˜åŸŸ: ${area}

åˆ¶ç´„:
- Tier: ${REFACTOR_TIER}
- PRã‚µã‚¤ã‚ºã‚¬ãƒ¼ãƒ‰: å¤‰æ›´ãƒ•ã‚¡ã‚¤ãƒ«æ•° <= ${MAX_CHANGED_FILES}, å·®åˆ†è¡Œæ•° <= ${MAX_CHANGED_LINES}
- package-lock.json ã¨ .github/workflows/ é…ä¸‹ã¯å¤‰æ›´ã—ãªã„
- æ—¢å­˜æŒ™å‹•ã‚’å£Šã•ãªã„ï¼ˆæŒ™å‹•å¤‰æ›´ãŒå¿…è¦ãªã‚‰ç†ç”±ã‚’æ˜è¨˜ã—ã€ãƒ†ã‚¹ãƒˆã‚’è¿½åŠ /æ›´æ–°ã™ã‚‹ï¼‰
- scopeã‚’åºƒã’ã™ããªã„ï¼ˆsmallã¯ç‰¹ã«1-3ãƒ•ã‚¡ã‚¤ãƒ«ä¸­å¿ƒï¼‰

ãƒ•ã‚¡ã‚¤ãƒ«:
${fileContents
  .map(
    (f) => `
--- ${f.path} (approx ${f.lines} lines) ---
${f.content}
`,
  )
  .join("\n")}

ä¸Šè¨˜ã®ã‚³ãƒ¼ãƒ‰ã‚’åˆ†æã—ã€ä»¥ä¸‹ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„:
1. ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°æ©Ÿä¼šã‚’ç‰¹å®š
2. å®Ÿéš›ã«ã‚³ãƒ¼ãƒ‰ã‚’æ”¹å–„ï¼ˆé‡è¤‡å‰Šé™¤ã€å‘½åæ”¹å–„ã€è¤‡é›‘åº¦å‰Šæ¸›ï¼‰
3. å¤‰æ›´å†…å®¹ã‚’JSONå½¢å¼ã§å‡ºåŠ›

IMPORTANT: Editãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã£ã¦å®Ÿéš›ã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿®æ­£ã—ã¦ãã ã•ã„ï¼

å‡ºåŠ›å½¢å¼:
{
  "refactored": true/false,
  "files_modified": ["path/to/file"],
  "changes_summary": "å¤‰æ›´å†…å®¹ã®èª¬æ˜",
  "area": "${area}"
}`;

  try {
    const result = await generateWithAI(
      REFACTORING_SPECIALIST.systemPrompt,
      userPrompt,
      { timeout: REFACTOR_TIMEOUT_MS },
    );

    // JSONæŠ½å‡º
    let jsonStr = result;
    const jsonMatch = result.match(/```(?:json)?\s*([\s\S]*?)```/);
    if (jsonMatch) {
      jsonStr = jsonMatch[1];
    }

    const refactoringResult = JSON.parse(jsonStr.trim());
    // Force consistency with the selected area (avoid model drift).
    refactoringResult.area = area;
    console.log("  âœ… Refactoring completed");
    console.log(`  ğŸ“ ${refactoringResult.changes_summary}`);

    return refactoringResult;
  } catch (error) {
    console.error("  âŒ Refactoring failed:", error.message);
    return null;
  }
}

function extractJsonFromOutput(text) {
  const jsonMatch = text.match(/```(?:json)?\s*([\s\S]*?)```/);
  return (jsonMatch ? jsonMatch[1] : text).trim();
}

async function judgeRefactorQuality(params) {
  const { area, attempt, threshold } = params;
  const changedFiles = getActionableChangedFiles();
  const fileStats = getFileStats(changedFiles);
  const newFiles = getNewFiles(fileStats);

  let diffStat = "";
  let diffPatch = "";
  try {
    diffStat = execSync("git diff --stat || true", {
      encoding: "utf-8",
      maxBuffer: 10 * 1024 * 1024,
    }).trim();
  } catch (_error) {
    diffStat = "";
  }

  try {
    diffPatch = execSync("git diff --unified=3 || true", {
      encoding: "utf-8",
      maxBuffer: 50 * 1024 * 1024,
    });
  } catch (_error) {
    diffPatch = "";
  }

  if (diffPatch.length > JUDGE_MAX_DIFF_CHARS) {
    diffPatch = `${diffPatch.slice(0, JUDGE_MAX_DIFF_CHARS)}\n\n[TRUNCATED]`;
  }

  const newFilesBlobs =
    newFiles.length > 0
      ? newFiles
          .map((f) => {
            const content = getFileContent(f).substring(0, 8000);
            return `--- ${f} ---\n${content}`;
          })
          .join("\n\n")
      : "(none)";

  const systemPrompt = `You are an LLM-as-a-Judge for automated refactoring PRs.

You must NOT modify files, run commands, or use any tools. You only evaluate the provided diff/context.
Be strict and prioritize safety (no behavior changes), scope discipline, and code clarity.

Return JSON only in this format:
{
  "score": 0-100,
  "summary": "one-paragraph summary",
  "must_fix": ["..."],
  "suggestions": ["..."]
}`;

  const userPrompt = `Judge the following refactor attempt.

Repo context: TypeScript/Next.js codebase.
Area: ${area}
Attempt: ${attempt}
Passing threshold: ${threshold}

Changed files (${changedFiles.length}):
${changedFiles.map((f) => `- ${f}`).join("\n") || "(none)"}

Diff stat:
${diffStat || "(empty)"}

Diff patch (may be truncated):
${diffPatch || "(empty)"}

New files content (truncated):
${newFilesBlobs}

Scoring rubric (0-100):
- Safety & correctness (0-40): behavior preserved, types ok, no risky changes
- Clarity & maintainability (0-30): naming/structure/DRY improvements
- Scope discipline (0-20): cohesive changes, no drive-by edits
- Testing & confidence (0-10): tests updated if needed, or rationale if not

Return JSON only.`;

  const before = getRepoStateFingerprint();
  const raw = await generateWithAI(systemPrompt, userPrompt, {
    timeout: 600000,
  });
  const after = getRepoStateFingerprint();
  if (before !== after) {
    throw new Error("Judge must be read-only (working tree changed).");
  }

  let parsed = null;
  try {
    parsed = JSON.parse(extractJsonFromOutput(raw));
  } catch (error) {
    return {
      score: 0,
      pass: false,
      threshold,
      summary: `Judge output was not valid JSON: ${error.message}`,
      must_fix: ["Judge output parse failed"],
      suggestions: [],
    };
  }

  const score = Number(parsed?.score);
  const normalizedScore = Number.isFinite(score)
    ? Math.max(0, Math.min(100, score))
    : 0;

  const mustFix = Array.isArray(parsed?.must_fix)
    ? parsed.must_fix
        .map((v) => `${v}`)
        .filter(Boolean)
        .slice(0, 20)
    : [];

  const suggestions = Array.isArray(parsed?.suggestions)
    ? parsed.suggestions
        .map((v) => `${v}`)
        .filter(Boolean)
        .slice(0, 20)
    : [];

  const summary = typeof parsed?.summary === "string" ? parsed.summary : "";

  return {
    score: Math.round(normalizedScore),
    pass: Math.round(normalizedScore) >= threshold,
    threshold,
    summary,
    must_fix: mustFix,
    suggestions,
  };
}

async function reviseRefactorAttempt(params) {
  const { area, attempt, threshold, judge, changedFiles } = params;
  const filesToShow = (changedFiles || []).slice(0, 5);
  const fileContents = filesToShow.map((file) => ({
    path: file,
    content: getFileContent(file),
  }));

  let diffPatch = "";
  try {
    diffPatch = execSync("git diff --unified=3 || true", {
      encoding: "utf-8",
      maxBuffer: 50 * 1024 * 1024,
    });
  } catch (_error) {
    diffPatch = "";
  }
  if (diffPatch.length > JUDGE_MAX_DIFF_CHARS) {
    diffPatch = `${diffPatch.slice(0, JUDGE_MAX_DIFF_CHARS)}\n\n[TRUNCATED]`;
  }

  const userPrompt = `å‰å›ã®ãƒªãƒ•ã‚¡ã‚¯ã‚¿çµæœãŒJudgeã§ä¸åˆæ ¼ã§ã—ãŸã€‚ã‚¹ã‚³ã‚¢ã‚’ ${threshold} ä»¥ä¸Šã«å¼•ãä¸Šã’ã‚‹ã‚ˆã†ã«ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚

é ˜åŸŸ: ${area}
Attempt: ${attempt}
Judge score: ${judge?.score ?? "unknown"}/${threshold}
Judge summary: ${judge?.summary ?? ""}

Must-fix:
${(judge?.must_fix || []).map((t) => `- ${t}`).join("\n") || "- (none)"}

Suggestions:
${(judge?.suggestions || []).map((t) => `- ${t}`).join("\n") || "- (none)"}

ç¾åœ¨ã®diff (truncated):
${diffPatch || "(empty)"}

åˆ¶ç´„:
- æ—¢å­˜æŒ™å‹•ã‚’çµ¶å¯¾ã«å£Šã•ãªã„
- ã‚¹ã‚³ãƒ¼ãƒ—ã‚’åºƒã’ãªã„ï¼ˆç„¡é–¢ä¿‚ãƒ•ã‚¡ã‚¤ãƒ«ã«è§¦ã‚‰ãªã„ï¼‰
- ä¾å­˜è¿½åŠ ã‚„ lockfile å¤‰æ›´ã¯ã—ãªã„
- å¿…è¦ãªã‚‰å¤‰æ›´ã‚’æˆ»ã—ã¦è‰¯ã„ï¼ˆå®‰å…¨/å¯èª­æ€§å„ªå…ˆï¼‰

å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆå¿…è¦ã«å¿œã˜ã¦ç·¨é›†ã—ã¦ãã ã•ã„ã€‚æœ€å¤§5ä»¶ã ã‘æ·»ä»˜ï¼‰:
${fileContents
  .map(
    (f) => `
--- ${f.path} ---
${f.content.substring(0, 10000)}
`,
  )
  .join("\n")}

IMPORTANT: Editãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã£ã¦å®Ÿéš›ã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿®æ­£ã—ã¦ãã ã•ã„ï¼

å‡ºåŠ›å½¢å¼(JSONã®ã¿):
{
  "refactored": true/false,
  "files_modified": ["path/to/file"],
  "changes_summary": "å¤‰æ›´å†…å®¹ã®èª¬æ˜",
  "area": "${area}"
}`;

  try {
    const raw = await generateWithAI(
      REFACTORING_SPECIALIST.systemPrompt,
      userPrompt,
      {
        timeout: REFACTOR_TIMEOUT_MS,
      },
    );
    const refactoringResult = JSON.parse(extractJsonFromOutput(raw));
    refactoringResult.area = area;
    return refactoringResult;
  } catch (error) {
    console.error("  âŒ Revision attempt failed:", error.message);
    return null;
  }
}

/**
 * git diffçµ±è¨ˆã‚’å–å¾—
 */
function getFileStats(files) {
  try {
    const stats = files.map((file) => {
      let tracked = false;
      try {
        execSync(`git ls-files --error-unmatch "${file}" 2>/dev/null`, {
          stdio: "ignore",
        });
        tracked = true;
      } catch (_error) {
        tracked = false;
      }

      const diffCmd = tracked
        ? `git diff --numstat HEAD -- "${file}" 2>/dev/null || echo "0\\t0\\t${file}"`
        : `git diff --numstat --no-index -- /dev/null "${file}" 2>/dev/null || echo "0\\t0\\t${file}"`;

      const diffStat = execSync(diffCmd, { encoding: "utf-8" }).trim();

      const [added, deleted, filePath] = diffStat.split("\t");
      return {
        path: file,
        added: parseInt(added) || 0,
        deleted: parseInt(deleted) || 0,
        isNew: !tracked,
      };
    });
    return stats;
  } catch (error) {
    console.warn("git diffçµ±è¨ˆå–å¾—å¤±æ•—:", error.message);
    return files.map((f) => ({ path: f, added: 0, deleted: 0, isNew: false }));
  }
}

/**
 * æ–°è¦ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—
 */
function getNewFiles(fileStats) {
  return fileStats.filter((f) => f.isNew).map((f) => f.path);
}

/**
 * åˆè¨ˆè¿½åŠ ãƒ»å‰Šé™¤è¡Œæ•°ã‚’å–å¾—
 */
function getTotalLines(fileStats) {
  return fileStats.reduce(
    (acc, f) => ({
      added: acc.added + f.added,
      deleted: acc.deleted + f.deleted,
    }),
    { added: 0, deleted: 0 },
  );
}

/**
 * PRã‚¿ã‚¤ãƒˆãƒ«ã‚’ç”Ÿæˆ
 */
function generatePRTitle(metadata) {
  const { area, newFiles, codeReduction } = metadata;

  // æ–°è¦ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ä¸»è¦ãªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåã‚’æŠ½å‡º
  const mainComponents = newFiles
    .map((f) => path.basename(f, path.extname(f)))
    .filter((name) => name.length > 0)
    .slice(0, 2)
    .join(", ");

  const reductionText = codeReduction > 0 ? ` - ${codeReduction}è¡Œå‰Šæ¸›` : "";
  const componentText = mainComponents ? ` - ${mainComponents}ä½œæˆ` : "";

  return `refactor(${area}): ${metadata.summaryShort}${componentText}${reductionText}`;
}

/**
 * PRãƒœãƒ‡ã‚£ã‚’ç”Ÿæˆ
 */
function generatePRBody(metadata, report) {
  const {
    area,
    fileStats,
    newFiles,
    linesAdded,
    linesDeleted,
    codeReduction,
    runNumber,
    runId,
    triggerEvent,
  } = metadata;
  const repoSlug = process.env.GITHUB_REPOSITORY || "Unson-LLC/brainbase";

  const newFilesSection =
    newFiles.length > 0
      ? newFiles
          .map((f) => {
            const stat = fileStats.find((s) => s.path === f);
            return `| \`${f}\` | +${stat?.added || 0} | æ–°è¦ä½œæˆ |`;
          })
          .join("\n")
      : "";

  const modifiedFilesSection = fileStats
    .filter((f) => !f.isNew)
    .map((f) => {
      return `| \`${f.path}\` | -${f.deleted}, +${f.added} | ãƒªãƒ•ã‚¡ã‚¯ã‚¿ |`;
    })
    .join("\n");

  return `## ğŸ“ å¤‰æ›´ã‚µãƒãƒªãƒ¼

**ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°é ˜åŸŸ**: ${area}
${metadata.judgeScore != null ? `\n**Judge Score**: ${metadata.judgeScore}/100 (threshold ${metadata.judgeThreshold})\n` : ""}

${report.split("## Changes Summary")[1]?.split("## Files Modified")[0]?.trim() || metadata.summary}

---

## ğŸ“Š å½±éŸ¿ç¯„å›²

### å¤‰æ›´ãƒ•ã‚¡ã‚¤ãƒ« (${fileStats.length}ä»¶)

| ãƒ•ã‚¡ã‚¤ãƒ« | å¤‰æ›´ | ç¨®é¡ |
|---------|------|------|
${newFilesSection}
${modifiedFilesSection}

### ã‚³ãƒ¼ãƒ‰å‰Šæ¸›åŠ¹æœ
**åˆè¨ˆ: ${codeReduction > 0 ? `ç´„${codeReduction}è¡Œå‰Šæ¸›` : `${Math.abs(codeReduction)}è¡Œå¢—åŠ `}** (-${linesDeleted}, +${linesAdded})

---

## ğŸ” ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒã‚¤ãƒ³ãƒˆ

### âœ… ç¢ºèªã—ã¦ã»ã—ã„ç‚¹
1. å¤‰æ›´å†…å®¹ã®å¦¥å½“æ€§
   - å‰¯ä½œç”¨ã‚„æŒ™å‹•å¤‰æ›´ãŒç´›ã‚Œã¦ã„ãªã„ã‹ï¼Ÿ

2. ä¾‹å¤–ç³»ãƒ»å¢ƒç•Œæ¡ä»¶
   - ã‚¨ãƒ©ãƒ¼å‡¦ç†ã‚„null/undefinedã®æ‰±ã„ãŒé©åˆ‡ã‹ï¼Ÿ

3. å‘½åãƒ»è²¬å‹™ã®åˆ†å‰²
   - åˆ†ã‹ã‚Šã‚„ã™ã„å‘½åã«ãªã£ã¦ã„ã‚‹ã‹ï¼Ÿ
   - è²¬å‹™ãŒéå‰°ã«åºƒãŒã£ã¦ã„ãªã„ã‹ï¼Ÿ

### âš ï¸ æ³¨æ„äº‹é …
- **ç ´å£Šçš„å¤‰æ›´ãªã—**: æ—¢å­˜ã®æ©Ÿèƒ½ã¯å…¨ã¦ä¿æŒã™ã‚‹å‰æ
- **ãƒ†ã‚¹ãƒˆ**: è¿½åŠ ãŒå¿…è¦ãªå ´åˆã‚ã‚Š

---

## ğŸ¤– è‡ªå‹•ç”Ÿæˆæƒ…å ±

<details>
<summary>è‡ªå‹•ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°è©³ç´°</summary>

- **ãƒ„ãƒ¼ãƒ«**: ops-department Auto Refactoring
- **Run Number**: ${runNumber}
- **Run ID**: ${runId}
- **å®Ÿè¡Œæ—¥æ™‚**: ${new Date().toISOString()}
- **ãƒˆãƒªã‚¬ãƒ¼**: ${triggerEvent}
- **ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼**: [${WORKFLOW_FILE}](https://github.com/${repoSlug}/actions/workflows/${WORKFLOW_FILE})

è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆ: ã“ã®PRæœ¬æ–‡ã®ã€Œå¤‰æ›´ã‚µãƒãƒªãƒ¼ã€ã«å«ã¾ã‚Œã¾ã™ã€‚

</details>`;
}

/**
 * ãƒ¡ã‚¤ãƒ³å‡¦ç†
 */
async function main() {
  const args = process.argv.slice(2);
  const dryRun = args.includes("--dry-run");
  const scanOnly = args.includes("--scan-only");

  if (scanOnly) {
    const allAreas = scanCodebase();
    console.log(`âœ… Found ${allAreas.length} areas`);
    console.log(
      allAreas
        .slice(0, 50)
        .map((a) => `- ${a}`)
        .join("\n"),
    );
    if (allAreas.length > 50) {
      console.log(`... (${allAreas.length - 50} more)`);
    }
    return;
  }

  console.log("ğŸ¤– ops-department Auto Refactoring Starting...");
  console.log("=".repeat(60));
  console.log(`Mode: ${dryRun ? "DRY RUN" : "PRODUCTION"}`);
  console.log("=".repeat(60));

  // 1. å±¥æ­´èª­ã¿è¾¼ã¿
  console.log("\nğŸ“– Loading refactoring history...");
  const history = loadRefactoringHistory();
  console.log(`  âœ… ${history.areas.length} history entries`);

  // 2. ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã‚¹ã‚­ãƒ£ãƒ³
  console.log("\nğŸ” Scanning codebase...");
  const allAreas = scanCodebase();
  console.log(`  âœ… Found ${allAreas.length} total areas`);

  console.log("\nğŸ”¥ Computing hotspots...");
  const hotspotScores = computeHotspotScores({ sinceDays: HOTSPOT_SINCE_DAYS });
  console.log(
    `  âœ… Hotspot window: last ${HOTSPOT_SINCE_DAYS} days (tier=${REFACTOR_TIER})`,
  );

  // 3. å¯¾è±¡é ˜åŸŸï¼ˆãƒ›ãƒƒãƒˆã‚¹ãƒãƒƒãƒˆå„ªå…ˆ + ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ï¼‰ã‚’é¸æŠ
  const eligibleAreas = findEligibleAreas(allAreas, history, {
    cooldownDays: COOLDOWN_DAYS,
  });
  console.log(
    `  âœ… ${eligibleAreas.length} eligible areas (cooldown ${COOLDOWN_DAYS} days)`,
  );

  if (eligibleAreas.length === 0) {
    console.log(
      "\nğŸ‰ No eligible areas found (all areas are within cooldown or have open PRs).",
    );
    return;
  }

  const targetArea = selectTargetArea(eligibleAreas, hotspotScores, {
    topN: TARGET_TOP_N,
  });
  if (!targetArea) {
    console.log("\nâš ï¸  Failed to select a target area.");
    return;
  }
  const files = getFilesInArea(targetArea);
  const hotspotScore = hotspotScores.get(targetArea) || 0;

  console.log(
    `\nğŸ¯ Target area: ${targetArea} (hotspot score: ${hotspotScore}, cooldown: ${COOLDOWN_DAYS}d)`,
  );

  const threshold = Math.max(0, Math.min(100, JUDGE_THRESHOLD));
  const maxAttempts = Math.max(1, JUDGE_MAX_ATTEMPTS);

  let refactoringResult = null;
  let judge = null;
  let changedFiles = [];

  for (let attempt = 1; attempt <= maxAttempts; attempt++) {
    if (attempt === 1) {
      refactoringResult = await refactorArea(targetArea, files);
    } else {
      refactoringResult = await reviseRefactorAttempt({
        area: targetArea,
        attempt,
        threshold,
        judge,
        changedFiles,
      });
    }

    if (!refactoringResult || !refactoringResult.refactored) {
      console.log("\nâŒ No refactoring was performed");
      discardWorkingTreeChanges();
      return;
    }

    changedFiles = getActionableChangedFiles();
    if (changedFiles.length === 0) {
      console.log(
        "\nâ„¹ï¸  No actionable code changes detected. Skipping PR creation.",
      );
      discardWorkingTreeChanges();
      return;
    }

    // Use git as source of truth (model output may drift).
    refactoringResult.files_modified = changedFiles;

    try {
      judge = await judgeRefactorQuality({
        area: targetArea,
        attempt,
        threshold,
      });
    } catch (error) {
      console.error("  âŒ Judge failed:", error.message);
      judge = {
        score: 0,
        pass: false,
        threshold,
        summary: `Judge failed: ${error.message}`,
        must_fix: [error.message],
        suggestions: [],
      };
    }

    console.log(
      `  ğŸ§ª Judge score: ${judge.score}/100 (threshold ${threshold})`,
    );

    if (judge.pass) {
      break;
    }

    if (attempt < maxAttempts) {
      console.log(
        `\nğŸ” Retrying to improve judge score... (${attempt + 1}/${maxAttempts})`,
      );
    }
  }

  if (!judge || !judge.pass) {
    console.log(
      `\nâŒ Judge threshold not met after ${maxAttempts} attempt(s). Discarding changes.`,
    );
    discardWorkingTreeChanges();
    return;
  }

  // 5. å±¥æ­´æ›´æ–°ã¯PRã¨ã¯åˆ†é›¢ã™ã‚‹ï¼ˆbaseãƒ–ãƒ©ãƒ³ãƒã¸ç›´æ¥ã‚³ãƒŸãƒƒãƒˆã™ã‚‹ã‚¹ãƒ†ãƒƒãƒ—ã§åæ˜ ã™ã‚‹ï¼‰
  const refactoringEntry = {
    area: refactoringResult.area,
    refactored_at: new Date().toISOString(),
    files_modified: refactoringResult.files_modified,
    changes_summary: refactoringResult.changes_summary,
    tier: REFACTOR_TIER,
    hotspot_since_days: HOTSPOT_SINCE_DAYS,
    hotspot_score: hotspotScore,
    cooldown_days: COOLDOWN_DAYS,
    refactor_timeout_ms: REFACTOR_TIMEOUT_MS,
    judge_score: judge.score,
    judge_threshold: judge.threshold,
    judge_summary: judge.summary,
    judge_must_fix: judge.must_fix,
    judge_suggestions: judge.suggestions,
    run_number: process.env.GITHUB_RUN_NUMBER || null,
    run_id: process.env.GITHUB_RUN_ID || null,
    trigger_event: process.env.GITHUB_EVENT_NAME || null,
  };
  fs.writeFileSync(RESULT_FILE, JSON.stringify(refactoringEntry, null, 2));
  console.log(`âœ… Refactoring result saved to ${RESULT_FILE}`);

  // 6. ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
  console.log("\nğŸ“„ Generating refactoring report...");
  const coveredAreas = new Set(
    (history.areas || [])
      .filter((entry) => entry && entry.area && entry.pr_status !== "closed")
      .map((entry) => entry.area),
  );
  coveredAreas.add(refactoringResult.area);

  const projectedCoveredCount = coveredAreas.size;
  const projectedHistoryEntries = (history.areas || []).length + 1;
  const remainingAreas = Math.max(0, allAreas.length - projectedCoveredCount);
  const report = `# ops-department Auto Refactoring Report

Generated: ${new Date().toISOString()}

## Refactored Area

**${refactoringResult.area}**

## Changes Summary

${refactoringResult.changes_summary}

## Judge

- Score: ${judge.score}/100 (threshold ${judge.threshold})
- Summary: ${judge.summary || "(none)"}
- Must-fix:
${judge.must_fix.length > 0 ? judge.must_fix.map((t) => `  - ${t}`).join("\n") : "  - (none)"}

## Files Modified

${refactoringResult.files_modified.map((f) => `- ${f}`).join("\n")}

## Progress

- Total areas: ${allAreas.length}
- Covered (unique): ${projectedCoveredCount}
- Remaining (unique): ${remainingAreas}
- Total runs (history entries): ${projectedHistoryEntries}
- Tier: ${REFACTOR_TIER}
- Hotspot score (last ${HOTSPOT_SINCE_DAYS}d): ${hotspotScore}

---

This refactoring was automatically performed by the ops-department refactoring-specialist.
`;

  const reportFileName = `ops-department-refactoring-${process.env.GITHUB_RUN_ID || Date.now()}.md`;
  const reportPath = process.env.GITHUB_ACTIONS
    ? path.join(process.env.RUNNER_TEMP || "/tmp", reportFileName)
    : "ops-department-refactoring.md";
  fs.writeFileSync(reportPath, report);
  console.log(`âœ… Report saved to ${reportPath} (not committed to git)`);

  // 7. PRãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”Ÿæˆ
  console.log("\nğŸ“ Generating PR message...");

  const fileStats = getFileStats(refactoringResult.files_modified);
  const newFiles = getNewFiles(fileStats);
  const totalLines = getTotalLines(fileStats);
  const codeReduction = totalLines.deleted - totalLines.added;

  const prMetadata = {
    area: refactoringResult.area,
    summary: refactoringResult.changes_summary,
    summaryShort: refactoringResult.changes_summary
      .split(/[ã€‚\n]/)[0]
      .substring(0, 60),
    fileStats,
    newFiles,
    linesAdded: totalLines.added,
    linesDeleted: totalLines.deleted,
    codeReduction,
    judgeScore: judge.score,
    judgeThreshold: judge.threshold,
    runNumber: process.env.GITHUB_RUN_NUMBER || "local",
    runId: process.env.GITHUB_RUN_ID || "unknown",
    triggerEvent: process.env.GITHUB_EVENT_NAME || "manual",
  };

  const prTitle = generatePRTitle(prMetadata);
  const prBody = generatePRBody(prMetadata, report);

  fs.writeFileSync("pr-title.txt", prTitle);
  fs.writeFileSync("pr-body.txt", prBody);

  console.log(`âœ… PR Title: ${prTitle}`);
  console.log("âœ… PR message saved to pr-title.txt, pr-body.txt");

  console.log("\n" + "=".repeat(60));
  console.log("ğŸ‰ ops-department Auto Refactoring Complete!");
}

main().catch((error) => {
  console.error("âŒ Fatal error:", error);
  process.exit(1);
});
