#!/usr/bin/env python3
"""
Contacts Migration Script
_codex/common/meta/contacts/data/*.csv â†’ Postgres graph_entities

Usage:
    python scripts/migrate_contacts_to_graph.py [--dry-run]
"""

import os
import sys
import csv
import json
import psycopg2
from datetime import datetime
from ulid import ULID

# Environment
DATABASE_URL = os.getenv('INFO_SSOT_DATABASE_URL') or os.getenv('INFO_SSOT_DB_URL')
if not DATABASE_URL:
    print("Error: INFO_SSOT_DATABASE_URL is not set", file=sys.stderr)
    sys.exit(1)

# Paths
CODEX_BASE = os.path.expanduser('~/workspace/shared/_codex')
CONTACTS_DIR = os.path.join(CODEX_BASE, 'common/meta/contacts/data')

CSV_FILES = [
    'eight_2024-12.csv',
    'scanned_2025-12.csv',
    'scanned_2026-01.csv'
]

def generate_contact_id():
    """Generate contact ID with cnt_ prefix"""
    return f"cnt_{ULID()}"

def normalize_csv_row(row, source_file):
    """Normalize CSV row to contact payload"""
    # Common fields
    payload = {
        'company_name': row.get('ä¼šç¤¾å', '').strip(),
        'department': row.get('éƒ¨ç½²å', '').strip(),
        'title': row.get('å½¹è·', '').strip(),
        'name': row.get('æ°å', '').strip(),
        'email': row.get('e-mail', '').strip(),
        'postal_code': row.get('éƒµä¾¿ç•ªå·', '').strip(),
        'address': row.get('ä½æ‰€', '').strip(),
        'tel_company': row.get('TELä¼šç¤¾', '').strip(),
        'tel_direct': row.get('TELç›´é€š', '').strip(),
        'mobile': row.get('æºå¸¯é›»è©±', '').strip(),
        'fax': row.get('Fax', '').strip(),
        'url': row.get('URL', '').strip(),
        'source_file': source_file,
        'source_type': 'eight' if 'eight' in source_file else 'scanned'
    }

    # Optional fields
    if 'ã‚¹ã‚­ãƒ£ãƒ³æ—¥' in row:
        payload['scanned_at'] = row.get('ã‚¹ã‚­ãƒ£ãƒ³æ—¥', '').strip()
    if 'ååˆºäº¤æ›æ—¥' in row:
        payload['exchanged_at'] = row.get('ååˆºäº¤æ›æ—¥', '').strip()
    if 'å‚™è€ƒ' in row:
        payload['notes'] = row.get('å‚™è€ƒ', '').strip()

    # Remove empty values
    return {k: v for k, v in payload.items() if v}

def read_csv_file(filepath, skip_lines=0):
    """Read CSV file and return rows"""
    contacts = []
    filename = os.path.basename(filepath)

    with open(filepath, 'r', encoding='utf-8-sig') as f:
        # Skip metadata lines
        for _ in range(skip_lines):
            next(f)

        reader = csv.DictReader(f)
        for row in reader:
            # Skip empty rows
            if not any(row.values()):
                continue

            payload = normalize_csv_row(row, filename)
            if payload.get('name'):  # Must have name
                contacts.append(payload)

    return contacts

def insert_contacts_to_graph(contacts, dry_run=False):
    """Insert contacts into graph_entities"""
    if dry_run:
        print(f"[DRY RUN] Would insert {len(contacts)} contacts")
        for i, contact in enumerate(contacts[:5], 1):
            print(f"  {i}. {contact.get('name')} ({contact.get('company_name')})")
        if len(contacts) > 5:
            print(f"  ... and {len(contacts) - 5} more")
        return

    conn = psycopg2.connect(DATABASE_URL)
    cur = conn.cursor()

    inserted = 0
    skipped = 0

    for contact in contacts:
        try:
            contact_id = generate_contact_id()
            payload_json = json.dumps(contact, ensure_ascii=False)

            cur.execute("""
                INSERT INTO graph_entities (
                    id,
                    entity_type,
                    project_id,
                    payload,
                    role_min,
                    sensitivity,
                    created_at,
                    updated_at
                ) VALUES (%s, %s, %s, %s, %s, %s, NOW(), NOW())
                ON CONFLICT (id) DO NOTHING
            """, (
                contact_id,
                'contact',
                None,  # contacts are not project-specific
                payload_json,
                'member',  # accessible by all members
                'internal'  # internal sensitivity
            ))

            if cur.rowcount > 0:
                inserted += 1
            else:
                skipped += 1

        except Exception as e:
            print(f"Error inserting contact {contact.get('name')}: {e}", file=sys.stderr)
            skipped += 1

    conn.commit()
    cur.close()
    conn.close()

    print(f"âœ… Inserted: {inserted}")
    print(f"âš ï¸  Skipped: {skipped}")
    print(f"ğŸ“Š Total: {len(contacts)}")

def main():
    dry_run = '--dry-run' in sys.argv

    if dry_run:
        print("ğŸ” DRY RUN MODE - No changes will be made\n")

    all_contacts = []

    # Read all CSV files
    for csv_file in CSV_FILES:
        filepath = os.path.join(CONTACTS_DIR, csv_file)
        if not os.path.exists(filepath):
            print(f"âš ï¸  Skipping {csv_file} (not found)")
            continue

        # eight_2024-12.csv has 3 metadata lines
        skip_lines = 3 if 'eight' in csv_file else 0

        contacts = read_csv_file(filepath, skip_lines=skip_lines)
        print(f"ğŸ“„ {csv_file}: {len(contacts)} contacts")
        all_contacts.extend(contacts)

    print(f"\nğŸ“Š Total contacts to import: {len(all_contacts)}\n")

    # Insert into database
    insert_contacts_to_graph(all_contacts, dry_run=dry_run)

    if dry_run:
        print("\nğŸ’¡ Run without --dry-run to actually insert data")

if __name__ == '__main__':
    main()
